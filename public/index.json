[{"content":"Hi, I\u0026rsquo;m Jack 👋 This is my first post. Welcome to my Blog\n","permalink":"http://zintrulcre.github.io/posts/my-first-post/","summary":"Hi, I\u0026rsquo;m Jack 👋 This is my first post. Welcome to my Blog","title":"My First Post"},{"content":"Hi, I\u0026rsquo;m Jack 👋 👤 Currently Software Development Engineer at Department of Education Victoria.\n📷 Enthusiastic in fitness, photography, travelling, reading \u0026amp; video games.\n📄 Checkout my resume: English / 简体中文\n✉️ Contact me at JackyWangMel96@gmail.com\n","permalink":"http://zintrulcre.github.io/about/","summary":"Hi, I\u0026rsquo;m Jack 👋 👤 Currently Software Development Engineer at Department of Education Victoria.\n📷 Enthusiastic in fitness, photography, travelling, reading \u0026amp; video games.\n📄 Checkout my resume: English / 简体中文\n✉️ Contact me at JackyWangMel96@gmail.com","title":"About"},{"content":"在海量数据中找到最大的 k 个数 对于少量的数据，想要找到最大的 k 个数只需要将数组排序并取出前 k 个数即可，但在实际应用中往往需要找到对海量数据（几亿或数十亿，假设数量为 n）进行操作，这时就需要采用一些更高效的办法。\n分块 如果不能同时将所有的数据全部载入内存，那么我们可以采用分治的思想，将所有数据分为大小相同的多份数据，分别进行操作。 我们可以将所有的 n 个数分成 m 份（例如将 1 亿个数分为 100 份），对每一份数据，找到其中最大的 k 个数，然后再对这 m * k 个数进行两两归并，找出其中最大的 k 个数。 如果没有多余的空间存储划分后的数据，那么可以直接采用哈希映射来将大文件中的数据分别映射到不同的小文件中。\n统计 对于找到每份数据内最大的 k 个数，最简单的方法是维护一个大小为 k 的小根堆并遍历所有的数。当堆的 size 小于 k 或堆顶元素小于当前的数时，将当前的数 push 进堆；当堆的 size 大于 k 时进行一次 pop 操作，删除堆顶元素。维护堆的时间复杂度是 O(logk)，遍历所有数的时间复杂度是 O(n)，所以总的时间复杂度是 O(nlogk)。 也可以使用类似于快速排序的方法，先确定一个 pivot 然后将数据分为左右两份，找到数组中所有小于 pivot 的数将他们置于 pivot 的左边。如果右边的个数大于 k，那么只需要继续对右边的数进行分治统计；如果右边的个数小于 k，那么右边的所有数都应该是结果，假设右边有 m 个数，现在只需要再对左边的数再进行分治统计，找到最大的 k - m 个数即可。这样平均时间复杂度是 O(nlogk)，最坏情况的时间复杂度是 O(kn)，最优情况的时间复杂度是 O(n)。\n哈希 ","permalink":"http://zintrulcre.github.io/posts/algorithms/top-k/","summary":"在海量数据中找到最大的 k 个数 对于少量的数据，想要找到最大的 k 个数只需要将数组排序并取出前 k 个数即可，但在实际应用中往往需要找到对海量数据（几亿或数十亿，假设数量为 n）进行操作，这时就需要采用一些更高效的办法。\n分块 如果不能同时将所有的数据全部载入内存，那么我们可以采用分治的思想，将所有数据分为大小相同的多份数据，分别进行操作。 我们可以将所有的 n 个数分成 m 份（例如将 1 亿个数分为 100 份），对每一份数据，找到其中最大的 k 个数，然后再对这 m * k 个数进行两两归并，找出其中最大的 k 个数。 如果没有多余的空间存储划分后的数据，那么可以直接采用哈希映射来将大文件中的数据分别映射到不同的小文件中。\n统计 对于找到每份数据内最大的 k 个数，最简单的方法是维护一个大小为 k 的小根堆并遍历所有的数。当堆的 size 小于 k 或堆顶元素小于当前的数时，将当前的数 push 进堆；当堆的 size 大于 k 时进行一次 pop 操作，删除堆顶元素。维护堆的时间复杂度是 O(logk)，遍历所有数的时间复杂度是 O(n)，所以总的时间复杂度是 O(nlogk)。 也可以使用类似于快速排序的方法，先确定一个 pivot 然后将数据分为左右两份，找到数组中所有小于 pivot 的数将他们置于 pivot 的左边。如果右边的个数大于 k，那么只需要继续对右边的数进行分治统计；如果右边的个数小于 k，那么右边的所有数都应该是结果，假设右边有 m 个数，现在只需要再对左边的数再进行分治统计，找到最大的 k - m 个数即可。这样平均时间复杂度是 O(nlogk)，最坏情况的时间复杂度是 O(kn)，最优情况的时间复杂度是 O(n)。\n哈希 ","title":"在海量数据中找到最大的 k 个数"}]